\subsection{Implementation}\label{redundancy_implementation}
In this section, we explain the objective and scope of the implementation, the functionality and the programming languages used.

The entire implementation is available in the GitHub repository \footnote{https://github.com/amirrabieyannejad/Redundancy\_Analysis/tree/main}.
%\subsubsection*{Objective and Scope}
%The goal and scope of the work is divided into four phases. Firstly, converting the USs annotated by the CRF tool into graph transformation rules; secondly, using the CDA tool of the Henshin to automatically report redundancies between USs pairwise; thirdly, extracting important information from the CDA report into a text report; fifthly, evaluation of reports. %For further analysis, we stored the information in a JSON file to be able to import the data into another platform such as Excel.
%Figure \ref{fig:implementation_phases} illustrates the mentioned implementation phases.
%\begin{figure}[h]
%	\centering
%	\includegraphics[scale=0.3]{implementation_phases}
%	%\includegraphics[scale=0.35]{sequence_diagram}
%	\caption{Three Implementation phases}\label{fig:implementation_phases}
%\end{figure} 
\subsubsection*{Methodology}
This section explains and introduces tools that are required during the development process.

Following approach and tools are necessary in order to develop our workflow:
\begin{itemize}	
	\item Java as programming language\footnote{https://www.java.com/de/}: Java is a widely used object-oriented programming language and software platform that is used to implement the Henshin and EMF APIs, which are critical to our approach to utilising them. Therefore, we use Java as our programming language.
	
	\item GitHub as version control\footnote{https://github.com/}: GitHub is a developer platform that allows developers to create, store, manage and share their code. It uses Git software, providing the distributed version control of Git plus access control, bug tracking, software feature requests, task management, continuous integration, and wikis for every project.
\end{itemize} 
\subsubsection*{Implementation Phases}\label{implementation_phases}
This section contains a step-by-step guide to implementation, starting with the set-up and ending with the final evaluation.
%\subsubsection*{Step 1: Data Preparation}\label{step_1}
%As primary input, we receive a graph-based model generated by the CRF tool, which represents the refined and annotated dataset for the recognition of \emph{entities}, \emph{actions}, \emph{persons} and \emph{benefits} of USs \cite{mosser2022modelling}.
%The datasets have the JSON format, the structure of which is very important in the Java classes \textit{RuleCreator}, \textit{ReportExtractor}, and \textit{Evaluation}. Therefore, understanding the JSON format provided is needed for the further procedure.
%Each JSON file for a backlog dataset contains a JSON-array in which each US entry is defined as a JSON-object. Listing \ref{list:json_format} illustrates the format used for the US entry.
%\begin{MyListing}
%	\paragraph{}
%	\hrule
%	\centering
%	\lstinputlisting[basicstyle=\ttfamily\footnotesize]{Listing/json_format.json}
%	\caption{The JSON format of each US entry in JSON file}\label{list:json_format}
%	\hrule
%\end{MyListing}
%Mooser et al. have linked each \emph{Persona} to each \emph{Primary Action} as \emph{Trigger} relationships, each \emph{Primary Actions} to each \emph{Primary Entity} as \emph{Target} relationships and each \emph{Primary/Secondary Entity} to each \emph{Primary/Secondary Entity} implying a \emph{Contains} relationship\cite{arulmohan2023extracting}.
%To interact with the entries in JSON file, we need to distinguish between the entries that are defined as JSON-objects, such as: {Text, Action, Entity, Benefit, US\_Nr} and the entries that are defined as a JSON-array, such as: {Persona, Primary/Secondary Action, Primary/Secondary Entity, Triggers, Targets, Contains}.
%In order to parsing JSON file, we use \enquote{org.json} library which provide us the classes as follow:
%\begin{itemize}
%	\item \enquote{JSONObject}: An unordered collection of key and value pairs.
%	\item \enquote{JSONArray}: Provide an ordered sequence of values.
%	\item \enquote{JSONTokener}: A tool that breaks a piece of text into a series of tokens that can be used by JSONObject or JSONArray to parse JSON entries.
%\end{itemize}
%\subsubsection*{Identifying USs in JSON-File}\label{workflow_nummerize_us}
%Annotated USs in each JSON file have no identifier. To distinguish USs, we use a Python script called \textit{nummerise\_us.py} \footnote{https://github.com/amirrabieyannejad/USs\_Annotation/tree/main/Script/numberise\_us}, which receives JSON files as input and adds a JSON object named \enquote{US\_Nr} with an identifier as value (e.g. user\_story\_01) to each US and returns the JSON files as output.
%Listing \ref{list:json_format_sample} illustrates the added JSON object "US\_Nr" and its value in the JSON file.
%\begin{MyListing}
%	\paragraph{}
%	\hrule
%	\centering
%	\lstinputlisting[basicstyle=\ttfamily\footnotesize]{Listing/json_format_sample.json}
%	\caption{The JSON format with the additional JSON object "US\_Nr" and its value}\label{list:json_format_sample}
%	\hrule
%\end{MyListing}
\subsubsection*{Creation of Rules}\label{step_creation_of_ruels}
In this section, we explain the methods we used to convert the US data structured in JSON files into transformation rules using the Henshin API. The process starts with the creation of an Ecore meta model, as explained in Section \ref{design_step_2}, which reflects the structure of the data. The henshin transformation rules are then generated using the RuleCreator class and its methods.
%\subsubsection*{Data Structures}
%The datasets of the backlogs annotated with the CRF tool have the JSON format, the structure of which is very important in the Java classes \textit{RuleCreator} and \textit{ReportExtractor}. Therefore, understanding the JSON format provided is crucial for the further procedure.

%Each JSON file for a backlog dataset contains a JSON-array in which each US entry is defined as a JOSN-object. Listing \ref{list:json_format} illustrates the format used for the US entry.
%\begin{MyListing}
	%\paragraph{}
	%\hrule
	%\centering
	%\lstinputlisting[basicstyle=\ttfamily\footnotesize]{Listing/json_format.json}
	%\caption{The JSON format of each US entry in JSON file}\label{list:json_format}
	%\hrule
%\end{MyListing}
%To interact with the entries in JSON file, we need to distinguish between the entries that are defined as JSON-objects, such as: {Text, Action, Entity, Benefit, US\_Nr} and the entries that are defined as a JSON-array, such as: {Persona, Primary/Secondary Action, Primary/Secondary Entity, Triggers, Targets, Contains}.
%In order to parsing JSON file, we use \enquote{org.json} library which provide us the classes as follow:
%\begin{itemize}
	%\item \enquote{JSONObject}: An unordered collection of key and value %pairs.
	%\item \enquote{JSONArray}: Provide an ordered sequence of values.
%	 \item \enquote{JSONTokener}: A tool that breaks a piece of text into a series of tokens that can be used by JSONObject or JSONArray to parse JSON entries.
%\end{itemize}
%Provide detailed explanations of key implementation aspects, such as algorithms, data structures, design patterns, and any custom solutions developed. Discuss any challenges faced during implementation and how you addressed them.
\subsubsection*{Methods of the RuleCreator Class}
In this section, the methods of the RuleCreator class is described as follows:
\begin{itemize}
	
	\item AssignCmodule: This method assign a CModule to a Ecore meta-model. It creates a new CModule object with the provided Henshin-file name, adds imports from the Ecore file, and returns the module.
	
	\item processJsonFile: It takes parsed JSON array as input and processes their attributes, such as persona, actions, entities, text and their edges, such as targets, triggers. Corresponding elements are created as output in a the Henshin transformation module (CModule).
	
	\item processRule: It takes the \enquote{US\_Nr} JSON-object as input and creates a new CRule with the name of unique US identifier in the CModule.
	
	\item processPersona: It receives as input the persona extracted from the JSON data and the associated CRule to create a new CNode representing the persona within the provided CRule and adds the attribute \enquote{name} with persona as value. Finally, the created CNode representing the persona is returned.
	
	\item processText: It receives as input US text extracted from JSON data and the associated CRule to create a new CNode representing the text within the provided CRule and adds the attribute \enquote{text} with US text as value. Finally, the created CNode representing the US text is returned.
	
	\item processActions: The processActions method is responsible for creating CNode objects that represent actions within the CModule. As parameters, it receives the JSON-object of the actions, the CNode-object representing the persona associated with the actions and the unique identifier of the US. Since the edge triggers only refer to the persona and the primary action, a new CNode is created for each primary action that represents the primary action within the provided CRule, an attribute \enquote{name} is added and an edge is created from the persona node to the primary action with the label \enquote{triggers}. For each secondary action, a new CNode is created to represent the action within the provided CRule and an attribute \enquote{name} is added to the action node.
	
	\item checkEntityIsTarget: It receives the name of the entity and the JSON-array with information about target edges. The method iterates through the JSON-array targets, which contains arrays that represent targets edges between actions and entities. It compares the targets entity with the specified entity. If there is a match, it returns true to indicate that the entity is a target.
	
	\item processEntities: It receives as parameters the JSON-object with information about the entities, the CRule object representing the US to which the entities belong and the JSON-array with information about the targets associated with the entities. The method checks whether primary/secondary entities are present, then creates a CNode for each primary/secondary entity and checks whether the entity is present in the target array. If this is the case, its attribute \enquote{name} is annotated for deletion. This method is used within the processContainsEdges method to determine whether an entity involved in a contains relationship is also a target of another entity.
	
	\item processContainsEdges: It receives the JSON-object to be processed, the JSON array with information about contains/target edges and the US identifier as parameters. It first checks whether both entities belong to contains edges. If both entities exist, an edge is created between them in CRule with the name \enquote{contains}. If one of the entities is a target of another entity (as specified in the targets array), the edge is annotated for deletion. If none of the entities is a target, the edge is annotated as \enquote{preserve}.
	
\end{itemize}
Figure \ref{fig:rule_creator_class_diagram} is a class diagram that illustrates the attributes, operations and relationships related to the RuleCreator class.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{rule_creator_class_diagram}
	\caption{Class diagram of the RuleCreator class and its relationships}\label{fig:rule_creator_class_diagram}
\end{figure}
%To illustrate this step, three example is given in which the RuleCreator class is applied to a dataset (G03) with three collected USs and the resulting artefact is presented.
%\begin{example}
%Listing \ref{list:json_user_story_12} shows the JSON format in relation to user\_story\_12 and Figure \ref{fig:rule_user_story_12} shows the application of the RuleCreator class in this US, which is a transformation rule where the targets and the associated contains relationships are annotated as a \textless Delete\textgreater action and the rest of the nodes and edges are annotated as a \textless Preserve\textgreater action.\\\\
%Text of US is:
%user\_story\_12: "\#G03\# As a Staff member, I want to Assign an Application for Detailed Review, so that I can review the for compliance and subsequently approved or denied."
%Considering the backlog dataset as shown in Listing \ref{list:backlog_g03}:
%\begin{MyListing}
%	\paragraph{}
%	\centering
%	\includegraphics[scale=0.8]{Listing/json_user_story_12.png}
%	\caption{JSON entities Related to %user\_story\_12}\label{list:json_user_story_12}
%\end{MyListing}
%\begin{figure}[h]
%	\centering
%	\includegraphics[scale=0.6]{rule_user_story_12}
%	\caption{Generated transformation rule related to user\_story\_12 using RuleCreator class}\label{fig:rule_user_story_12}
%\end{figure}
%As we can see, the "targets" edges and their direct relationships ("triggers" and "contain", if any) are also annotated as \textless delete\textgreater, which is very important to find redundant elements with the CDA tool.
%\end{example}
%\begin{example}
%Listing \ref{list:json_user_story_39} shows the JSON entities related to user\_story\_39 and Figure \ref{fig:rule_user_story_39} shows transformation rule generated by RuleCreator class.\\\\
%Text of US is:
%user\_story\_39: "\#G03\# As a Plan Review Staff member, I want to Review Plans, so that I can review them for compliance and either approve, or fail or deny the plans and record any conditions, clearances, or corrections needed from the Applicant."
%\begin{MyListing}
%	\paragraph{}
%	\centering
%	\includegraphics[scale=0.8]{Listing/json_user_story_39.png}
%	\caption{JSON entities Related to user\_story\_39}\label{list:json_user_story_39}
%\end{MyListing}
%\begin{figure}[h]
%	\centering
%	\includegraphics[scale=0.43]{rule_user_story_39}
%	\caption{Generated transformation rule related to user\_story\_39 using RuleCreator class}\label{fig:rule_user_story_39}
%\end{figure}
%Attribute "Plan", as we can see, it appears both in the main part as a primary entity and in the benefit part as a secondary entity, forming the various relationships as targets and contains.
%\end{example}

%\begin{example}
%Listing \ref{list:json_user_story_51} shows the JSON entities related to user\_story\_51 and Figure \ref{fig:rule_user_story_51} shows transformation rule generated by RuleCreator class.\\\\
%Text of US is:
%user\_story\_51: "\#G03\# As an Enforcement Staff member, I want to Issue a Notice of Violation, so that I can provide formal communication to the responsible party."
%\begin{MyListing}
%	\paragraph{}
%	\centering
%	\includegraphics[scale=0.8]{Listing/json_user_story_51.png}
%	\caption{JSON entities Related to user\_story\_51}\label{list:json_user_story_51}
%\end{MyListing}
%\begin{figure}[h]
%	\centering
%	\includegraphics[scale=0.55]{rule_user_story_51}
%	\caption{Generated transformation rule related to user\_story\_51 using RuleCreator class}\label{fig:rule_user_story_51}
%\end{figure}
%Last but not least, we have determined that the secondary entity "responsible party" has neither a target nor a contains relationship. Therefore, it is not annotated as \textless delete\textgreater, but as \textless preserve\textgreater. This is due to the fact that some phrases have been identified as entities in the CRF tool, but their relationship is not annotated at all, which is problematic for analysing redundancy.
%\end{example}
\subsubsection*{Report Extraction}\label{step_report_extraction}
In order to extracting a textual report associated with a specific backlog, we implement a class called \textit{ReportExtractor} within the package \textit{org.henshin.backlog.code.report}, which include the following classes form the package \textit{org.eclipse.emf.ecore}\footnote{https://download.eclipse.org/modeling/emf/emf/javadoc/2.7.0/org/eclipse/emf/ecore/}. These classes are important for reading the content of minimal-model.ecore:
\begin{itemize}
	
	\item org.eclipse.emf.ecore.resource.Resource: A resource of an appropriate type is created by a resource factory; a resource set indirectly creates a resource using such a factory. A resource is typically contained by a resource set, along with related resources.
	
	\item org.eclipse.emf.ecore.resource.ResourceSet: A resource set manages a collection of related resources and notifies about changes to this collection. It provides a tree of content. A collection of adapter factories supports the search for an adapter via a registered adapter factory. 
	
	\item org.eclipse.emf.ecore.EObject: EObject is the root of all modelled objects, therefore all method names start with "E" to distinguish the EMF methods from the client methods. It provides support for the behaviour and functions that are common to all modelled objects.
	
	\item org.eclipse.emf.ecore.EPackage: A representation of the model object \enquote{EPackage}.
	
	\item org.eclipse.emf.ecore.EClassifier: A representation of the model object \enquote{EClassifier}.
	
	\item org.eclipse.emf.ecore.EClass: A representation of the model object \enquote{EClass}.
	
	\item org.eclipse.emf.ecore.EAttribute: A representation of the model object \enquote{EAttribute}.
	
	\item org.eclipse.emf.ecore.EReference:  A representation of the model object \enquote{EReference}.
	
\end{itemize}
\subsubsection*{Storing Redundancy Items into RedundancyItems Class}
To save the redundant elements found by the CDA tool, we implement classes to save the elements according to their type.

Figure \ref{fig:redundancyItems_class_diagram} is a class diagram that illustrates the attributes, operations and relationships related to the ReundancyItems class to store the redundancy elements provided by the CDA tool.
\begin{figure}[h]
	\centering 
	\includegraphics[scale=0.36]{redundancyItems_class_diagram.png}
	\caption{Class diagram for the RedundancyItems class and its relationship}\label{fig:redundancyItems_class_diagram}
\end{figure} 
The following classes were created to represent the extracted model object accordingly. All these classes are extensions of the class \textit{RedundancyItems}, which contains all extracted model object from \enquote{minimal-model.ecore} such as \enquote{EClass}, \enquote{EAttribute} or \enquote{EReference}:
\begin{itemize}
	
	\item PrimaryAction/SecondaryAction: Which has only saved the EClass specified by \enquote{Primary/Secondary Action} and the EAttribute model object with the methods \textit{getType} to retrieve the saved EClass and \textit{getName} to retrieve the saved EAttribute.
	
	\item PrimaryEntity/SecondaryEntity: Which has only saved the EClass specified by \enquote{Primary/Secondary Entity} and the EAttribute model object with the methods \textit{getType} to retrieve the saved EClass and \textit{getName} to retrieve the saved EAttribute.
	
	\item Targets: The EClass specified by \enquote{Primary/Secondary Action} as \textit{outgoing edge} and an EAttribute model object as \textit{incoming edge} with \enquote{Primary/Secondary Entity}. The method \textit{getType} retrieve the stored EClass and method \textit{getName} retrieve the stored EAttribute.
	
	\item Contains: The EClass specified by \enquote{Primary/Secondary Entity} as \textit{outgoing edge} and an EAttribute model object as \textit{incoming edge} with \enquote{Primary/Secondary Entity}. The method \textit{getType} retrieve the stored EClass and method \textit{getName} retrieve the stored EAttribute.
	
	\item Triggers: The EClass specified by \enquote{Persona} as \textit{outgoing edge} and an EAttribute model object as \textit{incoming edge} with \enquote{Primary Action}. The method \textit{getType} retrieve the stored EClass and method \textit{getName} retrieve the stored EAttribute.
	
	\item RedundantPair: Stores the identifier of the two USs that were founded as a redundant pair. It also stored the total count of redundancy clauses within the US-pair.
	
	\item TargetsPair: Stores effective value of \enquote{\textit{Primary/Secondary Action}} and \enquote{\textit{Primary/Secondary Entity}} in action and entity fields accordingly.
	
	\item ContainsPair: Stores effective value of \enquote{\textit{Primary/Secondary Entity}} as \enquote{\textit{parent/child entity}} due to the fact that parent entity is a containment of child entity.
	
	\item TriggersPair: Stores effective value of \enquote{\textit{Persona}} as a persona and \enquote{\textit{Primary Action}} as an action.
	
\end{itemize}
The class RedundancyItems contains following methods which are important for class ReportExtractor:
\begin{itemize}
	\item isInCommonContains: This method is designed to determine whether a given entity (specified by its name) is part of a redundant pair listed in the \enquote{Contains} array of related USs stored in a JSON file.
	
	As input, it receives the name of the entity for which we want to Checks whether it exists in a redundant pair. In addition, a list of redundant pair objects that represent pairs of entities where one entity contains the other. If there is a match with the parent entity, it returns the child entity and vice versa.
	\item isInCommonTargets: This method is responsible for determining whether a particular action/entity is part of a redundant pair listed in the "Targets" array of related USs stored in a JSON file.
	
	As input, it receives the name and type of the first element, which is an action, and the name and type of the second element, which is an entity. It also receives a list of TargetsPair objects, which are pairs of common actions and entities between US-pairs.
	
	For each pair, it checks whether the specified names and types match either the action or entity in the pair. If a match is found, the method returns \textit{true}, which means that the specified elements are part of a redundant pair.
	\item printRedundantItems: This method is responsible for creating a report on redundancy items based on the data stored in the class instance. 
	
	As input, it takes several parameters, including a "FileWriter" to write to the textual report's file, lists of different pairs of "Targets", "Contains" and "Triggers", and a JSON-object to store the report data in JSON format, which is vital for evaluation.
\end{itemize}
\subsubsection*{ReportExtractor Class: Methods related to Extracting Redundancy Items}
To extract the redundant elements and save them in a redundancyItems object, we must first iterate through all existing \textit{minimal-mode.ecore} files and extract the redundant reduandcy item from each EPackage.

Figure \ref{fig:report_extractor_class_diagram} is a class diagram that illustrates the attributes, operations and relationship related to the extraction of redundancy items founded by the CDA tool and their storage in a RedundancyItems object.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.27]{report_extractor_class_diagram}
	\caption{Class diagram for the process of extracting redundancy items}\label{fig:report_extractor_class_diagram}
\end{figure} 

The following methods in the ReprortExtractor class are responsible for extracting the redundancies found by the CDA tool:
\begin{itemize}
	\item extractReports: This method orchestrates the extraction and analysis of created CDA report from a directory containing conflicted US-pairs and their associated reasons(conflict reason), and generates both text and JSON reports for further investigation and processing.
	
	It receives two FileWriter objects as input, one for writing textual and one for JSON reports.
	
	It iterates through each directory in the main directory that represents a conflict pair and uses the \textit{checkIfReportExist} method to make sure that the current US-pair are not already proceeded and the \textit{containsAnd} method to Checks whether it contains the conjunction \enquote{AND} to make sure that it is the valid US-pair name(\textit{e.g.} "user\_stroy\_12\_AND\_user\_stroy\_39" is a valid directory name).
	
	For each valid conflict pair directory, it iterates through the conflict reason directories within the current conflict pair directory and uses the \textit{minimalEcoreExist} method to Checks whether a \textit{minimal-model.ecore} file exists with reference to a conflict reason.
	
	To identify redundancy items, it uses the method \textit{processMinimalModels} and reads the "minimal-model.ecore" file, processes its content and iterates over the contained EPackages in order to process them further with the method \textit{iteratePackages}, which saves all redundancy items in RedundacyItems object.
	
	In addition, the methods \textit{hasEntitys}, \textit{hasActions} and \textit{hasTargets} are used to Checks whether the identified elements contain "Primary/Secondary actions" and "Primary/Secondary Entities" with common "Targets" reference. If the identified elements fulfil the criteria, the redundancy pair is included in the report.
	
	It then writes the potentially redundant USs and their clauses to the textual as well as JSON report files for further analysis.
	
	As output, the method returns a list of RedundantPair objects containing information about identified redundancies between US-pairs.
	
	\item createOrOverwriteReportFile: The method is responsible for creating or overwriting report file. It first ensures the existence of a report file. If the file doesn't exist, it creates a new one; if it already exists, it overwrites the existing file. Finally, it returns a \textit{FileWriter} to allow writing to the report file.
	
	\item checkIfReportExist: This method takes two parameters, namely US-pair and the list of all previously processed pairs in the CDA report directory. It returns \textit{true} if the US-pair was found in the pairList, which means that a report with the specified pairs has already been executed and therefore does not need to be executed again.
	
	\item minimalEcoreExist: This method checks the existence of a \textit{minimal-model.ecore} file using a conflict pair and a conflict reason generated by CDA tool.
	
	As input, it receives a conflict pair and a conflict reason. Using these parameters, the method constructs the file path to the minimal-model.ecore file and checks whether the file exists under the constructed path.
	
	If the ECore file exists, the method returns \textit{true}, indicating that the minimal-model.ecore file exists for the examined conflict pair and conflict reason. If the file does not exist, \textit{false} is returned.
	
	\item containsAnd: This method ensures that the folder name is identified with "\textit{\_AND\_}", as the report generated by CDA tool is formatted like \enquote{user\_story\_\textless digit \textgreater \_AND\_ user\_story\textless digit \textgreater}. It returns \textit{true} if the examined directory contains \enquote{AND}, otherwise \textit{false} is returned.
	
	\item processMinimalModels: This method reads a Minimal Model Ecore file, processes its content and iterates over the contained EPackages in order to process them further with the \textit{iteratePackages} method. 
	
	As parameters, it receives a File object that represents examined minimal model ecore file, an array list in which the names of the redundant elements are stored, and a RedundancyItems object that is used to handle redundant elements. 
	
	First, a ResourceSet and a ResourceFactoryRegistry corresponding to the minimal model Ecore file are set up and a Resource object is created from the Ecore file; the \textit{iteratePackages} method is called for each EPackage.
	
	\item iteratePackages: This method identifies redundancies within the attributes and references of EClasses in examined minimal model, stored them accordingly and updates the RedundancyItems object.
	
	It takes several parameters, such as the EPackage to be iterated over, an array list in which the names of the redundant elements are stored, and a RedundancyItems object. 
	
	It iterates through every EClassifier in the minimal package that contains EClasses and checks whether \enquote{\#} is present in EClass; if this is the case, EClass has been recognised as a conflict by CDA tool.
	
	If an attribute is found, the class of the conflicting attribute is determined and added to the corresponding element within RedundancyItems (e.g. Primary/Secondary Action/Entity). 
	
	Each EReference is then iterate through in the EClass. Depending on the reference name, the reference is added to the corresponding element within RedundancyItems (e.g. Triggers, Targets, Contains). The method is completed once all EClassifiers within the specified EPackage have been processed.
	
	\item hasActions: This method is useful for using the data stored in RedundancyItem to determine whether certain actions are present in a list of redundant entries, in order to later Checks whether the identified elements fulfil the criteria and the redundancy pair is included in the report.
	
	It checks if there's a match with name of any primary/secondary action stored in the RedundancyItems object. If match is found, it immediately returns \textit{true}.
	
	\item hasEntitys: This method is used to determine whether certain secondary/primary entities  are present in the RedundancyItems object based on their name. For each item, it checks whether there is a match with the name of a primary/secondary entity stored in the RedundancyItems object. 
	
	If a match is found, \textit{true} is returned immediately, in order to later Checks whether the identified elements fulfil the criteria and the redundancy pair is included in the report.
	
	\item hasTargets: This method uses the content of a RedundancyItems object to determine whether targets are present in a list of founded redundant elements.
	
	As input, it receives an array list with the names of the redundant elements and an object of the type RedundancyItems, which contains a collection of founded "Targets".
	
	The method checks whether there is a match with the name of any targets reference stored in the RedundancyItems object. 
	
	If a match is found between the elements, the method immediately returns \textit{true}, which means that at least one targets reference is present, in order to later Checks whether the identified elements fulfil the criteria and the redundancy pair is included in the report.
	
	\item readJsonArrayFromFile: This method provides the ability to read JSON data from a file and convert it into a JSONArray object, handling cases where the file is empty or does not exist.
	
	It receives the file path of the JSON file to be read as input. An attempt is made to open the specified file and Checks whether the file is empty or does not exist. If the file exists and is not empty, it reads the JSON data from the file and creates a JSON array object from the JSON data read from the file and returns the JSON array object with the JSON data.
	
	
	\item getRedundancyStatus: This method add statistics like count of main/benefit/total redundancies into JSON report. It receive as input redundancyItems and as output write the count of main/benefit/total redundancies into JSON report already defined in method highlightRedundancies.
\end{itemize}
\subsubsection*{Methods for Extracting Data from Dataset of Backlog}
To get information about USs such as text, redundant clauses in targets/contains/triggers references between US-pairs, we need to extract data from the dataset stored in the JSON file.
%Figure \ref{fig:json_data_extractor_diagram} illustrate the communication between three processes.
%\begin{figure}[h]
%\centering 
%\includegraphics[scale=0.35]{data_extractor_diagram}
%\caption{Sequence diagram for the processes of extracting common entries between two USs from dataset of the %backlog}\label{fig:json_data_extractor_diagram}
%\end{figure} 

The following methods in the ReprortExtractor class are responsible for extracting data from dataset within JSON file:
\begin{itemize}
	\item readJsonArrayFromFile: This method receives a JSON file as input. After reading, the JSON content is tokenised, parsed into a JSON array and the parsed JSON array is returned.
	
	\item getUssTexts: This method ensures that the text of the specified US-pair is retrieved from the JSON file and properly assigned to the RedundancyItems object for further processing. It receives a US-pair and RedundancyItems as input. 
	
	It reads a JSON array from a file using the \textit{readJsonArrayFromFile} method, iterates over each JSON object in the array and compares the extracted US identifier with the US identifier extracted from the input US-pair. If a match is found, the text of the first and second USs is set in the redundancyItems object.
	
	\item getCommonTargets: Used to determine overlaps in "Targets" references (pairs of actions and entities) between specified US-pairs from a JSON file.
	
	It receives the identifiers of the US-pair as input. After it finds the US objects, it compares each pair of entries (actions and entities) in "Targets" references of the two USs and looks for matches.
	
	The output is the matches, i.e. the list of common pairs of actions and entities, in "Targets" reference.
	
	\item getCommonContains: Used to determine overlaps in "Contains" references (pairs of entities) between specified US-pairs from a JSON file.
	
	It receives the identifiers of the US-pair as input. After it finds the US objects, it compares each pair of entities in "Contains" references of the two USs and looks for matches.
	
	The output is the matches, i.e. the list of common pairs of entities, in "Contains" reference.
	
	\item getCommonTriggers: Used to determine overlaps in "Triggers" references (pairs of personas and actions) between specified US-pairs from a JSON file.
	
	It receives the identifiers of the US-pair as input. After it finds the US objects, it compares each pair of entries (personas and actions) in "Triggers" references of the two USs and looks for matches.
	
	The output is the matches, i.e. the list of common pairs of personas and actions, in "Triggers" reference.
\end{itemize}
\subsubsection*{Methods for Highlighting Words using Hash Symbol(\#)}
In order to distinguish redundancy words between a US-pair, in text of each US, we decide to highlighting redundant words using hash symbol like \enquote{ ... \#\textless word\textgreater\# ... }.
%Figure \ref{fig:highlight_diagram} is a sequence diagram that illustrates the communication between processes related to the highlighting of redundancy words.
%\begin{figure}[h]
%\centering 
%\includegraphics[scale=0.35]{highlight_diagram}
%\caption{Sequence diagram for the process of highlighting redundancy clauses in the Texts of US-pair}\label{fig:highlight_diagram}
%\end{figure} 

The following methods in the ReprortExtractor class are responsible for highlighting redundancy words:
\begin{itemize}
	\item writeUsText: This method reads the text of examined US-pair, highlights redundant element between them using \textit{highlightRedundancies} method, writes the highlighted text to a file, and records information about the redundant elements. 
	
	As input it receive a US-pair, a list of redundant pairs to store redundant pairs in it, an object RedundancyItems containing stored redundancy elements and a FileWriter object used for writing output.
	
	It extract the identifier of the two USs from US-pair, retrieves the text of the USs from JSON file and add them to RedundancyItems, invoke the \textit{highlightRedundancies} method to identify and highlight redundants between the USs, it writes the highlighted text of each US to the FileWriter. Finally, sets the redundant pair and count of redundancy clauses.
	\item highlightRedundancies: This method identifies redundancies between US-pair, applies hash symbols using \textit{applyHashSymbols} method to highlight common items and updates the redundancy counts in the redundancyItems object. 
	
	It takes two parameters, redundancyItems and US-pair, which represents the pair of USs to be analysed. 
	
	It checks whether both USs contain a main clause part or whether one of them has a benefit part or whether both USs also have a benefit part.
	
	It applies hash symbols to common elements that only occur in the part of the USs that occurs in the same part (e.g. only main or only benefit part of the USs). 
	
	In each condition, it checks if there are redundancy clauses in the main part, then persona is also highlighted using \textit{applyHashSymbolPersona} method. It also updates the count of main/benefit/total redundancies and sets the changed text of USs. Finally, it returns the updated redundancyItems object.
	\item applyHashSymbols: This method is used to mark certain words within a substring with hash symbols (\#) at the beginning and end to ensure that they are distinguishable and can be easily identified or processed later. 
	
	It takes a substring in which replacements are to be made and a field of matches containing the words to be surrounded with hash symbols. First, the field of matches is sorted in descending order of length and processed accordingly to avoid adding hash symbols to unwanted clauses. 
	\begin{example}
		For example, let's assume that we have \enquote{data} and \enquote{data format} as redundancy elements. If we continue first with \enquote{data} and then with \enquote{import data}, \enquote{import data} will be replaced by \enquote{import \#data\#}, which is not desired.
	\end{example}
	\item hasMoreThanFour/SixHashSymbols: These methods receive a text from the US as input. They are used to Checks whether there are redundant clauses in the main part of the sentence (it can be one or two clauses). If so, \textit{true} is returned.
	
	\item applyHashSymbolPersona: This method identifies common "Triggers" references, marks them with hash symbols and returns the changed text parts together with the count of redundant triggers references. 
	
	As input, it receives a list of common triggers between US-pair, RedundancyItems and the parts of the USs. It iterates through the list of common triggers and checks whether both elements(persona and primary action) of the triggers are present in both parts. 
	
	It then increments the redundancy count to keep track of the count of redundant triggers. The output returned, is the text of USs containing the manipulated text parts with hash symbols and the redundancy count in main part.
	
	\item applyHashSymbolTargets: This method identifies common targets references between two parts of USs, marks them with hash symbols and returns the changed text parts together with the count of redundant targets references.
	
	As input, it receives a list of common targets between the US-pair, RedundancyItems and the parts of the USs. 
	
	It iterates through the list of common targets and checks whether both elements (primary/secondary action and primary/secondary entity) of the targets are present. It then increments the redundancy count in examined part of USs to keep track of the count of redundant targets. 
	
	The output returned is the text of USs containing the manipulated text parts with hash symbols and the redundancy count in examined part(main or benefit).
	
	\item applyHashSymbolContaians: This method identifies common contains references between two parts of USs, marks them with hash symbols and returns the changed text parts together with the count of redundant contains references. 
	
	As input, it receives a list of common contains between the US-pair, RedundancyItems and the parts of the USs. It iterates through the list of common contains and checks whether both elements of the contains are present in both parts. It then increments the redundancy count to keep track of the count of redundant contains.
	
	The output returned is the text of USs containing the manipulated text parts with hash symbols and the redundancy count in examined part(main or benefit).
	
\end{itemize}
\subsubsection*{Methods related to Report Divided Parts of USs}
To show which part of the USs with redundancy words occur between a US-pair, we have split the individual parts of the USs and included them in the report.
%Figure \ref{fig:splitUsText_diagram} is a sequence diagram that illustrates the communication between processes related to the splitting of parts of a US-pair containing redundancy words.
%\begin{figure}[h]
%\centering 
%\includegraphics[scale=0.35]{splitUsText_diagram}
%\caption{Sequence diagram for the process of splitting parts of US-pair containing redundancy word}\label{fig:splitUsText_diagram}
%\end{figure} 
The following methods in the ReprortExtractor class are responsible for splitting and reporting the parts of the USs :
\begin{itemize}
	
	\item splitUsText: This method is used to split the text of two USs into separate sections based on the occurrence of redundancy clauses. 
	
	The input is the text of the first and second US and their corresponding identifiers, a FileWriter for writing to a file and a JSON object for processing JSON data. 
	
	It splits each US text into three parts using commas and saves the result in arrays. It iterates over parts of the first and second USs and searches for occurrences of hash symbol pairs. For each part, the number of hash symbol pairs found is counted. Finally, all parts of the records that contain hash symbols are written to a text file and a JSON file as well.
	
	\item writeUsSentencePart: This method facilitates the extraction and storage of highlighted USs parts from US-pair in a textual report file for further analysis.
	
	As input, it receives the US-pair, RedundancyItems and a FileWriter allowing the extracted USs parts to be written. It receives the text of the USs from the reundancyItems object and calls the \textit{splitUsText} method to split the US-pair texts into USs parts with highlighted elements.
	
	The extracted USs parts are also written to the text and JSON report files, using the FileWriter for further processing and analysis.
	
	\begin{example}
		Take, for example, the following US-pair:
		
		\textit{user\_story\_60:} \#g22\# as an it staff member, I want to \#know\# \#how\# the \#data\# is \#used\#, so that I can determine what kind of basic services and functionalities are required.\\\\
		\textit{user\_story\_04:} \#g22\# as a data manager, I want to \#know\# \#how\# the \#data\# is \#used\#, so that I can develop more detailed usage and support scenarios with researchers.\\\\
		The following sentence parts are candidates for possible redundancies between user stories:\\\\
		user\_story\_04:  I want to \#know\# \#how\# the \#data\# is \#used\#\\\\
		user\_story\_60:  I want to \#know\# \#how\# the \#data\# is \#used\#	
	\end{example}
\end{itemize}
\subsubsection*{Methods related to Creating Table}
The summary of potential redundancy between US-pairs is presented in a table, which makes it easy to find out which US-pairs have been identified as potentially redundant US-pairs and how many redundancy elements there are in total.
%Figure \ref{fig:writeTable_diagram} is a sequence diagram that illustrates the communication between the processes related to creating tables and addition to text reports.
%\begin{figure}[h]
%\centering 
%\includegraphics[scale=0.35]{writeTable_diagram}
%\caption{Sequence diagram for the process of creating and adding tables to the textual report}\label{fig:writeTable_diagram}
%\end{figure} 
The following methods in the ReprortExtractor class are responsible for creating a table at the beginning of the text report:
\begin{itemize}
	\item writeTable: This method is used to write a table of potential redundancies between USs and the count of their total redundant clauses \textit{createTable} method.%, including the addition of the count of main and benefit redundancy clauses using \textit{createTable} method.
	
	As input, it receives a File object into which the table is inserted and a list of redundancy pairs containing information about redundant clauses in US-pars.
	
	It reads the existing content of the textual report file into a StringBuilder. It creates a table to display the potential redundancies between USs and the count of total redundancy clauses.
	
	The table headers and contents are generated based on the redundant pairs. It calculates the maximum width for each column in the table to ensure proper formatting. Finally, the table content is written to the FileWriter, followed by the existing content stored in the report's StringBuilder.
	
	\item createTable: This method prepares the content for the table in which potential redundancies between USs are displayed, taking into account the total redundancy count between each US-pairs based on the RedundantPair objects provided.
	
	As input, it receives a list of unique US-pairs for which the table is to be created and a list of RedundantPair objects containing information about redundant clauses between US-pairs.
	
	It initialises a two-dimensional array containing the contents of the table. The size of the table is determined by the count of unique pairs of USs plus one for the header row and column.
	
	It fills the header row and the first column of the table with unique pairs of US-pairs, replacing \enquote{user\_story} with \enquote{us} for the purpose of brevity.
	
	It calculates the maximum redundancy count between each US-pair by calling the method \textit{getTotalRedundanciesFromPair}. Finally, it fills the table with the total redundancy count. 
	
	The output is a two-dimensional array representing the contents of the table, with each cell containing the maximum redundancy count between the corresponding pair of USs.
	
	\item getTotalRedundanciesFromPair: This method makes it easier to retrieve the total number of redundancies between a US-pair from a list of RedundantPair objects.
	
	As input, it receives a list of RedundantPair objects containing information about redundant elements in US-pairs, where the first and second USs are to be compared.
	
	It iterates through each RedundantPair object in the RedundantPairs list and checks for each RedundantPair object whether the examined US-pair matches as redundant US-pair. 
	
	If a matching pair is found, the maximum redundancy number stored in this RedundantPair object is returned. If no matching pair is found, \textit{zero} is returned, indicating that there are no redundancies between the examined US-pair.
\end{itemize}
\subsubsection*{Report Evaluation}\label{step_report_evaluation}
The Evaluation class, found in the \textit{org.henshin.backlog.code.evaluation} package, was created to assess redundancy levels in USs based on JSON reports. This class includes methods that evaluate whether two USs are fully or partially redundant, focusing on various application components within these USs.

Figure \ref{fig:evaluation_class_diagram} is a class diagram that illustrates the attributes, operations of the Evaluation class and its relationship to other classes.
\begin{figure}[h]
	\centering 
	\includegraphics[scale=0.4]{evaluation_class_diagram}
	\caption{Class diagram related to Evaluation class}\label{fig:evaluation_class_diagram}
\end{figure} 
The class offers a detailed mechanism to evaluate redundancy through following methods:
\begin{itemize}
	\item\textit{evaluateRedundancyCriteria}: This method compares elements such as "Triggers", "Targets" and "Contains" in the "Main" and "Benefit" parts of USs. The method checks whether these clauses are fully redundant (i.e. they are identical between USs) or partially redundant (i.e. they share some clauses but are not fully identical).
	
	As input, it receives the JSON object for a specific US-pair.
	
	In particular, it checks various conditions, e.g. whether common clauses are present, whether targets or contains are empty and whether the clauses in the stories are fully or partially identical.
	
	As output, the method updates the JSON report with new keys indicating the redundancy status:
	
	Main Part Fully Redundant: A Boolean value indicating whether the "main part" of the USs is fully redundant.
	
	Main Part Partially Redundant: A Boolean value that indicates whether the "main part" of the USs is partially redundant.
	
	Benefit Part Fully Redundant: A Boolean value that indicates whether the "benefit part" of the USs is fully redundant.
	
	Benefit Partially Redundant: A Boolean value that indicates whether the "benefit part" of the USs is partially redundant.
	
	\item checkPartialRedundancy: The method processes these arrays to identify partial redundancy by checking whether elements from arrays of elements match elements from another array. 
	
	It receives the two arrays of elements as input, iterates through each element of the first input array and compares each of these elements with all elements in the second input array. A match counter records how often elements from the first input array find a match in the second input array.
	
	As output, method returns a Boolean value. True: indicates that there is at least one matching element pair between the two JSON arrays, which means partial redundancy. False: indicates that there are no matching elements, indicating no partial redundancy between these specific parts of the USs.
	
	\begin{example} Assume we have the following JSON arrays for two different USs: \\\\
		First JSON array: [["login", "button"], ["help", "link"]]\\
		Second JSON array:	[["logout", "button"], ["help", "link"]]\\\\
		The method would determine that the second element of the first array ("help", "link") matches the second element of the second array. As there is at least one match, checkPartialRedundancy would return true, indicating partial redundancy.
	\end{example}
	
	
	\item getJSONArraySafely: This method is designed to handle JSON operations safely by retrieving JSON array from a JSON object without the risk of throwing exceptions if the specified key does not exist.
	
	As input it receives the JSON object from which the JSON array needs to be extracted and a key corresponding to the JSON array within the provided JSON object.
	
	The method first checks whether the provided key exists in the JSON object. If the key exists, it retrieves the JSON array associated with that key. If the key does not exist, it returns an empty JSON array.
	\begin{example} Let's assume that a JSON object representing USs details should contain the key for "Benefit Part", which does not exist:\\
		\{\\
		"Common Targets" : \{\\
		"Main Part" : [["login","button"],["help","link"]]
		\}\\
		\} \\\\
		If the "Benefit Part" in the "Common Targets" needs to be accessed that does not exist, this is handled safely with \textit{getJSONArraySafely} by returning an empty array to avoid runtime errors.
	\end{example}
	
	\item readJsonArrayFromFile: The method enables JSON data to be read from a file and converted into a JSON array object. It takes the file path as input and attempts to open the file, checking whether the file is empty or missing. If the file is available and contains data, this data is read, converted into a JSON array object and returned.
	
\end{itemize}
\subsubsection*{Error Handling}
There were erroneous data in datasets that force us to handle them correctly. Therefore, we implement/use the following exceptions to accurately distinguish and handle them.

The following classes, which extend the \textit{Exception} class, are used in the \textit{org.henshin .backlog.code.rule} package and relate to error handling related to the JSON entries in the dataset of the backlogs and to the Ecore meta-model required to create the rules based on it:
\begin{itemize}
	\item EmptyOrNotExistJsonFile: Is triggered if the JSON file could not be found in the file system.
	
	\item ActionInJsonFileNotFound: Is triggered if the entry \textit{Action}, which contains \textit{Primary/Secondary Actions}, is not present in the JSON file and its absence should be reported.
	
	\item EntityInJsonFileNotFound: Is triggered if the entry \textit{Entity}, which contains \textit{Primary/Secondary Entity}, is not present in the JSON file and its absence should be reported.
	
	\item PersonaInJsonFileNotFound: Is triggered if the entry \textit{Persona} does not exist in the JSON file for a specific US.
	
	\item TextInJsonFileNotFound: Is triggered if the entry \textit{Text} does not exist in the JSON file for a specific US. 
	
	\item UsNrInJsonFileNotFound: Is triggered if the entry \textit{Us\_Nr} does not exist in the JSON file for a specific US.

	\item EdgeWithSameSourceAndTarget: Refers to the creation of edges in graph transformation rules and is triggered if the source and target of the edge have already been created, then the duplicate edge should be avoided.
		
	\item TargetsInJsonFileNotFound: Is triggered if the entry \textit{Targets} does not exist in the JSON file for a specific US.
	
	\item ContainsInJsonFileNotFound: Is triggered if the entry in \textit{Contains} is not present as \textit{Primary/Secondary Entity} in the JSON file and its absence should be reported.
	
	\item TriggersInJsonFileNotFound: Is triggered if the entry \textit{Triggers} does not exist in the JSON file for a specific US. 
	
	\item EcoreFileNotFound: Is triggered if the required ECore meta-model file could not be found and should also be reported.
\end{itemize}
Within the \textit{org.henshin.backlog.code.report} package, special classes that extend the \textit{Exception} class are designed to solve problems related to the CDA report directory, which encapsulates all US-pairs together with the associated conflict reasons. These classes include:
\begin{itemize}
	\item CdaReportDirIsEmpty: This exception is called if the CDA report directory is found but has no content.
	\item CdaReportDirIsNotADirectory: This exception is thrown in scenarios where the path provided for the CDA report directory is either not a directory (e.g. it is a file) or the specified path does not lead to a directory.
	\item CdaReportDirNotFound: This exception is triggered if the CDA report directory cannot be found within the specified path.
\end{itemize}
\subsubsection*{Limitations}
There are technical limitations that are causing us to change our implementation strategy.
The following limitations should be clarified at the beginning:
\begin{itemize}
	\item Use Eclipse version 2023-03, as Henshin version 4 cannot be installed with the latest version of Eclipse.
	
	\item Working with Java as the programming language, as the Henshin and CDA APIs are only available in the Java programming language.
	
	\item CDA API is not yet implemented to take into account conflicts and dependencies for attributes that are crucial for our approach. This forces us to use the CDA graphical user interface(GUI) instead of the CDA API.
	
	\item Lack of Henshin documentation regarding methods and classes, which makes it time consuming to understand the methods and make the right decision.
\end{itemize}
\subsection{Test}\label{redundancy_test}
Our objectives in this section include validating certain functions, checking the system requirements and ensuring the reliability and robustness of the implemented classes and methods.

As part of our testing strategy, we perform unit tests with \textit{JUnit} version 4\footnote{https://junit.org/junit4/}, which we selected for its compatibility with Eclipse version 2023-03. 

EclEmma\footnote{https://www.eclemma.org/} We have integrated a code coverage tool into the Eclipse IDE to ensure thorough testing and coverage. With the help of EclEmma, we systematically measured the effectiveness of our test suites and determined the test coverage for each individual class.
\subsubsection*{Configuration of Test Environment}
In the main project \textit{org.henshin.backlogconflict}, we create a separate package called \textit{org.henshin. backlogconflict.test}. This package contains the following Java classes, which correspond to the respective Java source code files:
\begin{itemize}
	
	\item JSONTransformerTest
	
	\item ActionsAnnotationsCreatorTest
	
	\item VerbFinderTest
	
	\item ReportMakerTest
	
\end{itemize}
\subsubsection*{Scope of Testing}
The scope of the tests depends on the system requirements and the implemented classes and their methods. The implemented error handling classes are also tested.
\subsubsection*{Test Cases and their Code Coverage}
We describe the individual test cases that are carried out during the test process. Each test case contains a description of the test scenario, the data provided and the expected result. To refine and improve our test cases, we used a code coverage report created by EclEmma to increase coverage and ensure a more reliable, error-resistant application.

Table \ref{tb:test_cases_json_transformer} shows the test cases for the JSONTransformer.java class and Figure \ref{fig:code_coverage_json_transformer} shows the code coverage.

%\newgeometry{margin=2.5cm}
%\begin{landscape}
\thispagestyle{empty}
%\begin{figure}[h]
\begingroup
\centering
\scriptsize
\renewcommand{\arraystretch}{1,5}
\keepXColumns
	\begin{tabularx}{\textwidth}{X  X  X  X}
	\hline
	Test Case &Supplied Data&Expected Outcome&Description\\
	\hline\hline
	\endfirsthead
	\hline
	Test Case &Supplied Data&Expected Outcome&Description\\
	\hline\hline
	\endhead
		BenefitNotExist&Assign USs without benefit part&The length of the entries(action, entity, contains, targets) for the benefit should be null&Check what happens if the US has no benefit part\\
		
		EntityInRelationNotFound \newline(Case1)&Preparing a JSON object whose entity entry is not defined as an entity in the relation entries assigned as the first reference&Through an exception: \textit{NullPointerException}&Checks whether the first referencing entity is already defined as an entity in the relation entries\\
		
		
		EntityInRelationNotFound \newline(Case2)&Preparing a JSON object whose entity entry is not defined as an entity in the relation entries assigned as the second reference&Through an exception: \textit{NullPointerException}&Checks whether the second referencing entity is already defined as an entity in the relation entries\\
		
		EmptyOrNotExistJsonFile&Assign an empty JSON file&Through an exception: \textit{NoSuchFileException}&Checks whether the JSON file is empty\\
		
		testPid&JSON file with the project ID&Create JSON object "PID" which contain the project ID of US&Checks whether the project ID was created as expected\\
		
		UnexpectedType&JSON file with a US with unexpected type&Through an exception: \textit{JSONException}&Checks whether the expected types (action, entity, text, etc.) in the corresponding US pass on in the JSON file and not unexpected\\
		
		
		\hline
		\caption{Test cases for JSONTransformer  class}\label{tb:test_cases_json_transformer}
	\end{tabularx}
	%\captionof{table}{Test cases for RuleCreator  class}\label{tb:test_cases_rule_creator}
\endgroup

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{code_coverage_json_transformer}
	%\includegraphics[scale=0.35]{sequence_diagram}
	\caption{Code coverage related to class JSONTransformer}\label{fig:code_coverage_json_transformer}
\end{figure} 


Table \ref{tb:test_cases_verb_finder} shows the test cases for the VerbFinder.java class and Figure \ref{fig:code_coverage_verb_finder} shows the code coverage.

%\end{figure}
%\end{landscape}
%\restoregeometry
%\newgeometry{margin=2.5cm}
%\begin{landscape}
	\thispagestyle{empty}
%	\begin{figure}[h]
		\begingroup
		\centering
		\scriptsize
		\renewcommand{\arraystretch}{1,5} 
		\keepXColumns
		\begin{tabularx}{\textwidth}{X  X  X  X}		
			\hline
			Test Case &Supplied Data&Expected Outcome&Description\\
			\hline\hline
			\endfirsthead
			\hline
			Test Case &Supplied Data&Expected Outcome&Description\\
			\hline\hline
			\endhead
			testLoadCSV\linebreak (Case1)&Assign a CSV file that contains two columns: one for verbs and one for action comments, so that both columns contain no empty cells&Action Annotation corresponds to verbs should be returned&Checks whether the action note has been returned accordingly in respect of the verb\\
			
			testLoadCSV\linebreak (Case2)&Assign a CSV file that contains two columns: one for verbs and one for action comments, so that one column contain empty cell&A verb without an assigned action annotation should be ignored&Checks whether the action annotation has been returned accordingly in respect of the verb\\
			\hline
				\caption{Test cases for VerbFinder class}\label{tb:test_cases_verb_finder}
		\end{tabularx}		
	%	\captionof{table}{Test cases for ReportExtractor  class}\label{tb:test_cases_report_extractor}
		\endgroup
	%\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{code_coverage_verb_finder}
	\caption{Code coverage related to class VerbFinder}\label{fig:code_coverage_verb_finder}
\end{figure} 

Table \ref{tb:test_cases_actions_annotations_creator} shows the test cases for the ActionsAnnotationsCreator.java class and Figure \ref{fig:code_coverage_actions_annotations_creator} shows the code coverage.

%\end{figure}
%\end{landscape}
%\restoregeometry
%\newgeometry{margin=2.5cm}
%\begin{landscape}
\thispagestyle{empty}
%	\begin{figure}[h]
	\begingroup
	\centering
	\scriptsize
	\renewcommand{\arraystretch}{1,5} 
	\keepXColumns
	\begin{tabularx}{\textwidth}{X  X  X  X}		
		\hline
		Test Case &Supplied Data&Expected Outcome&Description\\
		\hline\hline
		\endfirsthead
		\hline
		Test Case &Supplied Data&Expected Outcome&Description\\
		\hline\hline
		\endhead
		ActionsAnnotationsCreator&Assign a JSON file without entries of action annotations (target or contains action annotation)&Create action annotation related to target action annotated&Checks whether the JSON array for the corresponding action has been created for the target\\
		
		
		\hline
		\caption{Test cases for ActionsAnnotationsCreator class}\label{tb:test_cases_actions_annotations_creator}
	\end{tabularx}		
	%	\captionof{table}{Test cases for ReportExtractor  class}\label{tb:test_cases_report_extractor}
	\endgroup
	%\end{figure}
	
	\begin{figure}[h]
		\centering
		\includegraphics[scale=0.5]{code_coverage_actions_annotations_creator}
		\caption{Code coverage related to class ActionsAnnotationsCreator}\label{fig:code_coverage_actions_annotations_creator}
	\end{figure} 
	
Table \ref{tb:test_cases_report_maker} shows the test cases for the Evaluation.java class and Figure \ref{fig:code_coverage_report_maker} shows the code coverage.

%\newgeometry{margin=2.5cm}
%\begin{landscape}
%\thispagestyle{empty}
%\begin{figure}[h]
\begingroup
\centering
\scriptsize
\renewcommand{\arraystretch}{1,5} 
\keepXColumns

\begin{tabularx}{\textwidth}{X  X  X  X}
	\hline
	Test Case &Supplied Data&Expected Outcome&Description\\
	\hline\hline
	\endfirsthead
	\hline
	Test Case &Supplied Data&Expected Outcome&Description\\
	\hline\hline
	\endhead
	
	ActionAnnotation\newline InJsonFileNotFound&Provision of a JSON object without action annotation&Through an exception:\textit{ActionAnnotation InJsonFileNotFound}&Checks whether the JSON object provided contains an entry for action annotations\\
	
	TargetActionAnnotation\newline InJsonFileNotFound&Provision of a JSON object without target action annotation&Through an exception:\textit{ActionAnnotation InJsonFileNotFound}&Checks whether the JSON object provided has an entry for target action annotations\\
	
	ContainActionAnnotation\newline InJsonFileNotFound&Provision of a JSON object without contain action annotation&Through an exception:\textit{ActionAnnotation InJsonFileNotFound}&Checks whether the JSON object provided has an entry for contain action annotations\\
	
	EntityContainExist&Provision of a conflict pair with indirect conflict through contain relation&The US-pairs should be reported as a conflict pair&Checks whether the conflict is recognised if the entity from Us belongs to contain relation\\
	
	JsonArrayNotFound&Provision of a JSON file in which a JSON array is missing&Null should be return&Checks whether the specific JSON array was not found, if so, return null\\
	
	JsonObjectNotFound&Provision of a JSON file in which a JSON object is missing&Null should be return&Checks whether the specific JSON object was not found, if so, return null\\
	
	runReportMaker\_Main&Provision of two USs that contradict each other&The conflict pair should be reported in text form&Checks whether two USs that contradict each other have already been reported as conflict pair\\
	
	MainIsEmpty&Provision of a JSON object with empty main part entry&Through an exception:\textit{MainPartInJsonFile NotFound }&Checks whether the main part entry in provided JSON object is not empty\\
	
	MainNotExist&Provision of a JSON object without main part entry&Through an exception:\textit{MainPartInJsonFile NotFound }&Checks whether the JSON object provided has main part entry\\
	
	runReportMaker\_NoConflict&Provision of a set of USs that not contradict each other&The conflict pair should not be reported&Checks whether two USs that do not contradict each other should not be reported as a conflict pair\\
	
	UsNrInJsonFileNotFound&Provision of a JSON object that don't have US identifier&Through an exception:\textit{UsNrInJsonFileNotFound}&Checks whether the JSON object in the JSON file already has an identifier\\
	
	writeTable&Provision of a conflict pair that should be reported&Conflict pair should be listed in tabular form&Check whether the conflict pair is already listed in the table\\
	\hline
	\caption{Test cases for ReportMaker  class}\label{tb:test_cases_report_maker}
\end{tabularx}

%\captionof{table}{Test cases for RuleCreator  class}\label{tb:test_cases_rule_creator}
\endgroup
\thispagestyle{empty}
%\end{landscape}
%\restoregeometry

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{code_coverage_report_maker}
	%\includegraphics[scale=0.35]{sequence_diagram}
	\caption{Code coverage related to class ReportMaker}\label{fig:code_coverage_report_maker}
\end{figure}
%\subsubsection*{Performance Test}
%In this section, we describe the performance testing approach used for this project, including the test setup, key metrics, and the results of the tests.

\input{Section/Conflict_Evaluation}
