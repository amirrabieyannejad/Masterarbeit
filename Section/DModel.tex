\section{Preliminaries}\label{preliminaries}
%In this section, we present the techniques and tools in different domains which are required for our workflow. A comparative analysis \cite{nejad2023} has shown that these techniques and tools are the best and most suitable candidates for our approach in each area. In this section we discuss why these techniques are better than others. 

%of \emph{composable backlogs}, \emph{conditional random fields}, \emph{natural language processing}, \emph{VerbNet as a computational lexicon resource}, \emph{graph}, \emph{graph transformation rules}
In the \ref{dmodel} Section, we introduce \emph{conditional random fields} (CRF) for the extraction of domain models from agile product backlogs, which play a central role in effectively supporting the identification of dependencies and conflicts between user stories. Furthermore, we conduct a conclusion.

Next, we dive into the Section \emph{nlp} and introduce \emph{natural language processing} (NLP) and \emph{VerbNet} as a computational lexicon resource as well as a conclusion.

Finally, in Section \ref{gts}, some basic definitions of \emph{graphs} and \emph{graph transformation rules} are laid down for better understanding. We then look at the graph transformation tool \emph{Henshin} and its extension \emph{critical pair analysis} (CPA), which plays a central role in our methodology. We also draw a conclusion and explain why we have chosen these techniques and what their central idea is.

\subsection{Extracting Domain Models from Textual Requirements}\label{dmodel}
Automated support for extracting domain models from requirements artifacts such as USs play a central role in effectively supporting the detection of redundancies and conflicts between user stories. Domain models are a simple way to understand the relationship between artifacts and the whole system. In this subsection, we present a graph-based extraction modelling approach called CRF and conclude our review.
\subsection*{A Modelling Backlog as Composable Graphs} \label{composable_graph}
Mosser et al. propose a model engineering method (and the associated tooling) to exploit a graph-based meta-modelling and compositional approach. The objective is to shorten the feedback loop between developers and POs while supporting agile development’s iterative and incremental nature. 

The tool can extract what is called a conceptual model of a backlog in an ontology-like way. The conceptual models are then used to measure USs quality by detecting ambiguities or defects in a given story \cite{mosser2022modelling}.
From a modelling point of view, Mosser et al. represents the concepts involved in the deﬁnition of a backlog in a metamodel, as depicted in figure \ref{fig:conceptual_metamodel}. Without surprise, the key concept is the notion of story, which brings a benefit to a \emph{Persona} thanks to an Action performed on an \emph{Entity}. A Story is associated to a readiness \emph{Status}, and might optionally contribute to one or more \emph{QualityProperty} (\emph{e.g.}, security, performance).
\begin{figure}[h]
\centering
\includegraphics[scale=0.6]{Backlog_conceptual_metamodel}
\caption{Backlog conceptual metamodel \cite{mosser2022modelling}}\label{fig:conceptual_metamodel}
\end{figure}

Consider, for example, the following story, extracted from the reference dataset \cite{Dalpiaz2018}: \enquote{As a user, I want to click on the address so that it takes me to a new tab with Google Maps.}. \emph{This story brings to the user (Persona) the benefit of reaching a new Google Maps tab (Benefit) by clicking (Action) on the displayed address (Entity).}

As Entities and Personas implement the \emph{jargon} to be used while specifying features in the backlog, they are deﬁned at the \emph{Backlog level}. On the contrary, Actions belong to the associated stories and are not shared with other stories. Finally, a \emph{Product} is deﬁned as the \emph{Backlog} used to specify its features.

Mosser et al. propose in the context of backlog management a system which represented in figure \ref{fig:early_feedback} is proposed for utilization. Building upon the efficiency of NLP approaches. Mosser et al. suggest employing an NLP-based extractor to create a backlog model. This model will subsequently assist teams in the planning phase by aiding in the selection of stories for implementation during the upcoming iteration \cite{mosser2022modelling}.
\begin{figure}[h]
\center
\includegraphics[scale=0.5]{Providing_early_feedback_at_the_backlog_level}
\caption{Providing early feedback at the backlog level \cite{mosser2022modelling}}\label{fig:early_feedback}
\end{figure}
\subsection*{Composable Backlogs}
In order to support team customization (\emph{e.g.}, a given team might want to enrich the backlog metamodel with additional information existing in their product management system) Mossser et al. chose open-world(ontological) representation by modelling backlog as graphs \cite{mosser2022modelling}. The graph is equipped with constraints (\emph{e.g.}, a story always refers to a persona and an entity) to ensure that the minimal structure captured in the previously deﬁned metamodel is guaranteed.
\begin{definition}[\textbf{Story}]
A Story$s \in S$ is defined as a tuple $\left(P,A,E,K\right)$, where $P=\{p_1, ..., p_i\}$ is the set of involved personas, $A= \{a_1, ..., a_i\}$ the set of performed actions, and $E = \{e_1, ..., e_k\}$ the set of targeted entities. Additional knowledge (e.g., benefit, architectural properties, status) can be declared as key-value pairs in $K = \{(k_1,v_1), ..., (k_l,v_l)\}$. The associated semantics is that the declared actions bind personas to entities. Considering that story independence is a pillar of agile methods (as, by definition, stories are independent inside a backlog), there is no equivalence class deﬁned over \\
$S: \forall (s,s')\in S^2, s\neq s' \Rightarrow s \not \equiv s'$.
\end{definition}
\begin{definition}[\textbf{Backlog}]
A backlog $b \in B$ is represented as an attributed typed graph $b = (V, E, A)$, with $V$ a set of typed vertices, $E$ a set of undirected edges linking existing vertices, and $A$ a set of key-value attributes. Vertices are typed according to the model element they represent $v \in V, type(v) \in \{ Persona, Entity, Story \} )$ . Edges are typed according to the kind of model elements they are binding. Like backlogs, vertices and edges can contain attributes, represented as \emph{(key, value)} pairs. The empty backlog is denoted as $\emptyset = (\emptyset ,\emptyset ,\emptyset )$.
\end{definition}
\begin{example}\label{ex_2}
Backlog excerpt: Content Management System for Cornell University — CulRepo \emph{\cite{Dalpiaz2018}}.
\begin{itemize}
\item $s_1$: As a faculty member, I want to access a collection within the repository.
\end{itemize}
Associated model:
\begin{itemize}
\item $s_1 = (\{ faculty member \} ,\{ access\} ,\{ repository, collection\} ,\emptyset)\in S$
\end{itemize}
A backlog containing a single story $s_1$: (\enquote{As a faculty member, I want to access a collection within the repository}). \\ \\ 
$b_1=\left(V_1 , E_1,\emptyset \right ) \in B$ \\ 
$V_1=\left \{ Persona(faculty \ member, \emptyset \right )$ ,

\ \ \ \ $Stroy \left (s_1, \{ \left (action, access \right ) \} \right )$

\ \ \ \ $Entity \left (repository, \emptyset \right ) $,

\ \ \ \ $Entity(collection, \emptyset ) \} $ \\ 
$E_1 = \{ has\_for\_persona(s_1,faculty \ member)$,

\ \ \ \ $has\_for\_entity \left (s_1,repository \right )$

\ \ \ \ $has\_for\_entity(s_1, collection)\}$
\end{example}
%TODO: Intruduction of Doccano
\subsection*{Conditional Random Fields (CRF)}
CRFs \cite{Lafferty2001} are a particular class of \emph{Markov Random Fields}, a statistical modelling approach supporting the definition of discriminative models. They are classically used in pattern recognition tasks (labelling or parsing) when context is important identify such patterns \cite{arulmohan2023extracting}.

To apply CRF Mosser et al. transform a given story into a sequence of tuples. Each tuple contains minimally three elements: \emph{(i)} the original word from the story, \emph{(ii)} its syntactical role in the story, and \emph{(iii)} its semantical role in the story. The syntactical role in the sentence is classically known as \emph{Part-of-Speech} (POS), describing the grammatical role of the word in the sentence. The semantical role plays a dual role here. For training the model, the tags will be extracted from the annotated dataset and used as target. When used as a predictor after training, these are the data Mosser et al. will ask the model for infer.

The main limitations of CRF are that \emph{(i)} it works at the word level (model elements can spread across several words), and \emph{(ii)} it is not designed to identify relations between entities \cite{arulmohan2023extracting}.
    To address the first limitation, Mosser et al. use a glueing heuristic. Words that are consecutively associated with the same label are considered as being the same model element, \emph{e.g.}, the subsequence [\enquote{UI}, \enquote{designer}] from the previous example is considered as one single model element of type \emph{Persona}.
    
Mosser et al. applied this heuristic to everything but verbs, as classically, two verbs following each other represent different actions. They used again heuristic approach to address the second limitation. Mosser et al. bound every \emph{Persona} to every primary \emph{Action} (as\emph{ trigger} relations), and every primary \emph{Actions} to every primary \emph{Entity} (as \emph{target} relations) \cite{arulmohan2023extracting}.
\begin{example} Consider the following example:\\ \\
$S=[^\prime As^\prime,^\prime a^\prime,^\prime UI^\prime,^\prime designer^\prime,^\prime,^\prime,\ .\ .\ .]$ \\
$POS(S)=[ADP,DET,NOUN,NOUN,PUNCT,.\ .\ .]$ \\
$Label \left (S \right ) = \left [ \emptyset ,\emptyset ,PERSONA,PERSONA,\emptyset ,.\ .\ .\right ]$ \\\\
$S$ represents a given US (Table \ref{tb:feature_sets}). $POS \left (S \right )$ represent the Part-of-speech analysis of $S$. The story starts with an adposition (ADP), followed by determiner (DET), followed by a noun, followed by another noun, .... Then, $Lables\left (S \right )$ represents what we interest in: the first two words are not interesting, but the $3^{rd}\  and \ 4^{td}$ words represent a Persona.\\ 
\emph{A complete version of the example is provided in Table \ref{tb:feature_sets}.}
\end{example}
\begin{figure}[h]
\center
\includegraphics[width=\textwidth, height=2.76cm]{Example_of_annotated_user}
\caption{Example of annotated user using Doccano Annotation UI \cite{arulmohan2023extracting}}\label{fig:annot_usr}
\end{figure}
\begin{figure}[h]
\begingroup
\scriptsize
\begin{tabularx}{\textwidth}{c@{\hspace{4pt}} | c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}}
Word &As &a&\textcolor[rgb]{1.0, 0.0, 0.5}{UI}&\textcolor[rgb]{1.0, 0.0, 0.5}{designer}&, &I &want &to&\textcolor[rgb]{0.21, 0.46, 0.53}{begin}&\textcolor[rgb]{0.8, 0.33, 0.0}{user} &\textcolor[rgb]{0.8, 0.33, 0.0}{testing}&,\\
POS&	ADP&	DET	&\textcolor[rgb]{1.0, 0.0, 0.5}{NOUN}	&\textcolor[rgb]{1.0, 0.0, 0.5}{NOUN}	&PUNCT	&PRON	&VERB	&PART	&\textcolor[rgb]{0.21, 0.46, 0.53}{VERB}	&\textcolor[rgb]{0.8, 0.33, 0.0}{NOUN}	&\textcolor[rgb]{0.8, 0.33, 0.0}{NOUN}	&PUNCT \\
Label	&-	&-	&\textcolor[rgb]{1.0, 0.0, 0.5}{PER}	&\textcolor[rgb]{1.0, 0.0, 0.5}{PER}	&-	&-	&-	&-	&\textcolor[rgb]{0.21, 0.46, 0.53}{P-ACT}	&\textcolor[rgb]{0.8, 0.33, 0.0}{P-ENT}	&\textcolor[rgb]{0.8, 0.33, 0.0}{P-ENT}	&- \\
 \end{tabularx}
  \begin{tabularx}{\textwidth}{c}
  \\
  \end{tabularx}
 \begin{tabularx}{\textwidth}{c@{\hspace{4pt}} | c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}  c@{\hspace{4pt}}}
Word&	so	&that	&I	&can	&\textcolor[rgb]{0.09, 0.45, 0.27}{validate}	&\textcolor[rgb]{0.5, 0.0, 0.5}{stakeholder}	&\textcolor[rgb]{0.5, 0.0, 0.5}{UI}	&\textcolor[rgb]{0.5, 0.0, 0.5}{improvement}	&\textcolor[rgb]{0.5, 0.0, 0.5}{requests}	&. \\
POS	&SCONJ	&SCONJ	&PRON	&AUX	&\textcolor[rgb]{0.09, 0.45, 0.27}{VERB}	&\textcolor[rgb]{0.5, 0.0, 0.5}{NOUN}	&\textcolor[rgb]{0.5, 0.0, 0.5}{NOUN}	&\textcolor[rgb]{0.5, 0.0, 0.5}{NOUN}	&\textcolor[rgb]{0.5, 0.0, 0.5}{NOUN}	&PUNCT\\
Label	&-	&-	&-	&-	&\textcolor[rgb]{0.09, 0.45, 0.27}{S-ACT}	&\textcolor[rgb]{0.5, 0.0, 0.5}{S-ENT}	&\textcolor[rgb]{0.5, 0.0, 0.5}{S-ENT}	&\textcolor[rgb]{0.5, 0.0, 0.5}{S-ENT}	&\textcolor[rgb]{0.5, 0.0, 0.5}{S-ENT}	&-\\
 \end{tabularx}
\scriptsize \emph{POS tags are the Universal POS tags \\ 
Labels: PER (Persona), P-ACT (Primary Action), P-ENT (Primary Entity), S-ACT (Secondary Action), S-ENT (Secondary Entity)}
\captionof{table}{Minimal Feature Set, associating part-of-speech (POS) and semantic labels to each word in a given story \cite{arulmohan2023extracting}}\label{tb:feature_sets}
\endgroup
\end{figure}
\subsection*{Doccano Tool}\label{doccano}
Doccano\footnote{https://doccano.github.io/doccano} is an open-source annotation tool designed to facilitate the labelling and tagging of textual data for various Natural Language Processing tasks. Its user-friendly interface and versatile functionalities make it suitable for different annotation purposes, including Named Entity Recognition (NER), text classification, and sequence labelling. It supports collaborative annotation efforts, making it an ideal choice for projects requiring high-quality labelled datasets.

Doccano proved to be an effective tool for Mosser et al. in annotating USs, enabling them to create a reliable dataset with high interrater agreement. Its ease of use, collaborative features, and support for complex annotation schemes make it a valuable asset for any annotation project in the field of NLP.
\subsection*{ Annotating User Stories with Doccano}\label{annotaing_with_doccano}
Mosser et al. used publicly available requirements, focusing on a dataset from Dalpiaz et al.\cite{Dalpiaz2018}, which includes 22 product backlogs and 1,679 USs. This dataset is a raw archive of 22 text files, each containing USs for a product, one per line. They noted the absence of publicly available expert annotations providing ground truth for the dataset's concepts.

To address this, they manually annotated the dataset using the Doccano tool as a \textit{Named Entity Recognition} task. They applied labels such as persona, action, entity, and benefit part, along with two relations (triggers and contains) from their domain meta-model. Figure \ref{fig:annot_usr} shows example of annotated US using Doccano. Quality checks included:
\begin{itemize}
	\item Initial calibration on 75 randomly selected stories.
	
	\item Fortnightly validation sessions over two months.
	
	\item Manual review of 330 randomly selected annotated stories (19.6\%).
	
\end{itemize}
They found no significant discrepancies, with only 21 elements disputed, resulting in a 94\% interrater agreement, considered excellent.


\subsection*{Conclusion}\label{crf_conclusion}
The Conditional Random Fields (CRF) approach is graph-based and is designed to achieve a high degree of precision and recall, which is particularly important in the context of domain concept extraction. The CRF approach can encompass both syntactic and semantic aspects, particularly when complemented by a suitable conceptual meta-model. This makes it a suitable candidate for definition as a type graph in Henshin. 

However, due to the aforementioned limitations of the CRF tool, specifically the exclusion of secondary actions and entities within relations such as trigger and target, we opted for annotated datasets using Doccano presented by Mosser et al. This was because it labelled a greater number of relations such contains and targets, even between secondary actions and entities, which should facilitate precise evaluation in further analysis. 

The annotations generated by Doccano can then be utilised for transformation into a rule-based graph transformation system, which enhances support for DevOps practices.
\input{Section/NLP}
