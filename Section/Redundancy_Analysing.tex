\section{Analysing Redundancy}\label{redundancy}
% some explenation here about what will be explain here an why
%(Analyse von Redundanz als title und dann im Text Schreiben, dass es ein syntaktische Analyse ist
In this Section, we present an approach for syntactically analysing redundancy using the CRF tool and Henshin.

In Section \ref{redundancy_requirement} we illustrate the requirements and functional needs that are used as input to the design phase to satisfy and bring value and benefit to the stakeholder. In the Section \ref{desing} we explain the design decisions of the workflow shown in \ref{fig:workflow_diagram} and we explain how the architecture is structured and what the components and their classes look like. In Section \ref{redundancy_implementation} comes the implementation to show what we have implemented and in Section \ref{redundancy_tests} we show how we have tested it. Finally, we will apply this approach to 19 backlogs entered with the CRF tool\footnote{https://github.com/ace-design/nlp-stories} we enter all backlogs as input and the results are evaluated in section\ref{redundancy_evaluation}.
\subsection{Requirements}\label{redundancy_requirement}
In order to accomplish the analysis of redundancy in USs we try to address following requirements:
\begin{itemize}
\item As a member of a project group, I want to syntactically analyse USs that belong to a specific backlog, so that redundancies between USs can be recognise and manage accordingly.
\item As a member of a project group, I would like to have a collection of US-pairs as a report that syntactically have the same clause in parts of user stories, so that I can change them if necessary.
\item As a member of a project group, I want to filter the report and only see the redundancy clauses that contain \enquote{Action}(as a verb) and \enquote{Entity}(as a noun) which is called \enquote{Targets} that are duplicated in US-pair, so that I can reduce the number of potential redundancy pairs in the report.
\item As a member of a project group, I want to mark founded redundancy clauses with hash marks(\#) and list those that contain \enquote{Persona}(as a noun) and \enquote{Action}(as a verb) which is called \enquote{Triggers}, so that I can better see whether the Persona in is also recognised as a redundancy.
\item As a member of a project group, I want to mark justified redundancy clauses with hash marks (\#) and list those that contain \enquote{Entity}(as a noun) and \enquote{Entity}(as a noun), which is called \enquote{Contains}, so that I can better see whether the contained entity is also recognised as a redundancy.
\item As a member of a project group, I would like to have a redundancy report that shows substantiated clauses in US-pairs and adds a hash symbol (\#) at the beginning and end of the substantiated clauses as tag in each user story, so that I can see which words are duplicated in a part of the sentences.
\item As a member of a project group, I want to see how many clauses are in each US-pair, so that I can aggregate each redundant US-pair based on it.
\item As a member of a project group, I want a table at the top of the redundancy report that lists the US-pairs and the number of clauses contained in each pair, so that I can quickly see all the US-pairs founded and the number of clauses. 
\item As a member of a project group, I want to know whether the redundancy clauses belong to the main or benefit part of the US, so that I can make a decision accordingly.

\end{itemize}
% here should explain what was the reiquirement and why

\subsection{Design}\label{desing}
% what are the design decisions of this workflow that I had at the beginning, then describe what happens step by step, what translation I made, what is the main design decision you made for this translation, what question and that is part of the design
%In Desing should be how the architecture is based on which components and what is my own component, what does it use, what does the component look like, what class is there, is the class design, so everything comes from the Desing chapter
In this section we describing the sequence of workflow shown in \ref{fig:workflow_diagram} step-wise. Additionally, we explain what are the design decisions of this workflow and how the architecture is based on which components and classes.

To fulfil the requirements mentioned in \ref{redundancy_requirement}, we use the CRF tool \cite{mosser2022modelling} for the annotation of backlogs and the Henshin API \cite{arendt2010henshin} under Java programming language for the automatic generation of rules for each US in the backlog. Moreover, we use Henshin's CDA(conflict and dependency analysis) feature \cite{mens2007analysing} to automatically recognise conflicting US-pairs.\\\\
A detailed, step-by-step description of the workflow is given below:
\subsection*{CRF Tool}\label{workflow_crf}
As input, we receive a graph-based model generated by the CRF tool, which represents the refined and annotated dataset for the recognition of \emph{entities}, \emph{actions}, \emph{persons} and \emph{benefits} of USs \cite{mosser2022modelling}. Mooser et al. have linked each \emph{Persona} to each primary \emph{Action} (as \emph{Trigger} relationships), each primary \emph{Actions} to each primary \emph{Entity} (as \emph{Target} relationships) and each primary/secondary \emph{Entity} to each primary/secondary \emph{Entity} (implying a \emph{Contains} relationship)\cite{arulmohan2023extracting}. As output we receive a JSON-file which contains all annotated USs separated by each backlogs.
\subsection*{Identifying USs in JSON-File}\label{workflow_nummerize_us}
Annotated USs in each JSON-file have no identifier. To distinguish user stories, we use a Python script called \textit{nummerize\_us.py} \footnote{https://github.com/amirrabieyannejad/USs\_Annotation/tree/main/Skript/nummerize\_us}, which receives JSON-files as input and adds a JSON-object called \enquote{US\_Nr} with a number as value to each US and returns the JSON-files as output.
\subsection*{Creating Ecore Meta-Model}\label{workflow_ecore}
To be able to create rules in Henshin, an Ecore (meta)-model should be available. Ecore is the core (meta)-model at the heart of the EMF (Eclipse Modelling Framework). It enables the formulation of other models by utilising its constructs.
Accordingly, we create an Ecore meta-model as shown in Figure \ref{fig:ecore_meta_model}, which is inspired by the meta-model shown in Figure \ref{fig:conceptual_meta-model} and corresponds to the JSON-objects in the JSON-file as follows:
\begin{itemize}
	\item \textit{Persona} as a class in the meta-model corresponds to the JSON-object \enquote{Persona} in the JSON-file.
	\item \textit{Entity} as an abstract class, from which \textit{Primary/Secondary Entity} inherits as a class in the meta-model, corresponds to the JSON-object \enquote{Entity}, which contains two JSON arrays, namely \enquote{Secondary/Primary Entity} in the JSON-file.
	\item \textit{Action} as an abstract class and \textit{Primary/Secondary Action} as an inherited class in the meta-model correspond to the JSON-object \enquote{Action}, which contains two JSON arrays, namely \enquote{Secondary/Primary Action} in the JSON-file.
	\item \textit{Benefit} as a class in the meta-model, which also has an attribute called \enquote{text} that corresponds to the JSON-object \enquote{Benefit} in the JSON-file.
	\item \textit{Story} as a class in the meta-model, which also has an attribute called \enquote{text} that corresponds to the JSON-object \enquote{Text} in the JSON-file.
	\item Abstract class \textit{NamedElement} has attribute \textit{name}, which Primary/Secondary Action/entity inherit from it.
	\item \textit{Edge} with the name \textit{triggers} between Persona and primary action in the meta-model, which corresponds to the JSON array \enquote{Triggers}, where each JSON array in it contains a pair, the first element corresponding to the Persona and the second to the primary action.
	\item \textit{Edge} named \textit{targets} between Primary/Secondary Action and Primary/Secondary Entity in the meta-model, which corresponds to the JSON array \enquote{Triggers}, where each JSON array has a pair, the first element corresponding to \enquote{Primary/Secondary Action} and the second element corresponding to \enquote{Primary/Secondary Entity}.
	\item \textit{edge} named \textit{contains} between Primary/Secondary Action and Primary/Secondary Entity in the meta-model, which corresponds to the JSON array \enquote{contains}, where each JSON array in it has a pair where the first element corresponds to \enquote{Primary/Secondary Entity} and the second element corresponds to \enquote{Primary/Secondary Entity}.
\end{itemize}

\begin{figure}[h]
	\center
	\includegraphics[scale=0.5]{ecore_meta-model}
	\caption{Ecore meta-model inspired by Mosser et al. \cite{mosser2022modelling}}\label{fig:ecore_meta_model}
\end{figure} 
\subsection*{Creating Rules}\label{workflow_rule_creator}
With the identified USs in the the JSON-file, we generate rules with the Henshin package \textit{org.eclipse.emf.henshin.model. compact}, which is responsible for the creation of \textit{Transformation rules} and their \textit{Classes}, \textit{Attributes}, \textit{Edges} and annotates them with \textit{<Delete>}, \textit{<Create>} or \textit{<Preserve>}, which are crucial for the CDA tool to recognise the conflict pairs. 
To generating rules we create a package named \textit{package org.henshin.backlog.code.rule} and specially the class \textit{RuleCreator} which used following classes:
\begin{itemize}
	\item org.eclipse.emf.henshin.model.compact.CModule: which is responsible for assigning 
\end{itemize}



 
%\input{Section/Redundancy_Implementation}
